# Spotify Global Charts â€“ Serverless ETL on AWS

Automated ETL that pulls top songs from the Spotify Web API, stores raw JSON in S3, transforms to tabular data (artists, albums, songs), catalogs the schema with AWS Glue, and queries with Amazon Athena. Scheduled to run daily so you can roll up weekly insights (top tracks/artists/albums) across the year.

## âœ¨ Features

- Daily extraction from Spotify (search/playlists/tracks depending on your config)
- Durable raw zone in S3; idempotent transform with file move to `processed_data/`
- Clean normalized tables: `artists`, `albums`, `songs`
- Handles Spotifyâ€™s mixed album release date granularities (`year|month|day`)
- Glue Crawler + Data Catalog for Athena SQL analytics
- Packaged for AWS Lambda with a single dependency Layer (Spotipy + Pandas)

---

## ğŸ§  How it works (at a glance)

1. **Extract**  
   EventBridge (CloudWatch) daily cron â†’ **Lambda `data_extraction`** â†’ Spotify API â†’ write JSON to  
   `s3://<BUCKET>/raw_data/to_be_processed/`.

2. **Transform**  
   S3 ObjectCreated â†’ **Lambda `data_transformation`** â†’ parse/normalize â†’ write CSV/Parquet to  
   `s3://<BUCKET>/transformed_data/{artists_data|album_data|songs_data}/` and move raw JSON to  
   `s3://<BUCKET>/raw_data/processed_data/`.

3. **Load / Query**  
   **Glue Crawler** infers schema â†’ **Glue Data Catalog** â†’ **Athena** queries.

> You can aggregate daily results into weekly views in Athena (examples below).

---

## ğŸ—‚ï¸ Suggested repository layout

.
â”œâ”€ lambda/
â”‚ â”œâ”€ extraction/
â”‚ â”‚ â””â”€ lambda_function.py
â”‚ â”œâ”€ transform/
â”‚ â”‚ â””â”€ lambda_function.py
â”‚ â””â”€ layers/ # build scripts/zips for Spotipy & Pandas
â”œâ”€ sql/
â”‚ â”œâ”€ athena_example_queries.sql
â”‚ â””â”€ athena_create_views.sql
â””â”€ README.md

yaml
Copy code

---

## âœ… Prerequisites

- AWS account with access to **S3**, **Lambda**, **EventBridge**, **Glue**, **Athena**
- Python **3.11** Lambda runtime
- Spotify Developer app (Client ID/Secret)
- (Optional) AWS **Secrets Manager** entry with a **refresh token** if you need user-level endpoints  
  (some playlist endpoints require a user token rather than client-credentials)

---

## ğŸ”‘ Spotify setup

1. Create an app at <https://developer.spotify.com/dashboard>.  
2. Add this Redirect URI in the app **Edit Settings** (for local token generation):  
   `http://127.0.0.1:8888/callback`
3. (Optional, only if you need user endpoints) obtain a **refresh token** locally:

   ```python
   import spotipy
   from spotipy.oauth2 import SpotifyOAuth

   sp = spotipy.Spotify(auth_manager=SpotifyOAuth(
       client_id="YOUR_CLIENT_ID",
       client_secret="YOUR_CLIENT_SECRET",
       redirect_uri="http://127.0.0.1:8888/callback",
       scope="playlist-read-private playlist-read-collaborative"
   ))
   print("Logged in as:", sp.me()["display_name"])
   # Copy the refresh_token from the generated .cache file
Save credentials in Secrets Manager (recommended name: spotify/etl/creds):

json
Copy code
{
  "client_id": "xxxxx",
  "client_secret": "xxxxx",
  "redirect_uri": "http://127.0.0.1:8888/callback",
  "refresh_token": "xxxxx"
}
If you only use client-credentials flows, you donâ€™t need a refresh token.

## ğŸª£ S3 layout

perl

Copy code

s3://<BUCKET>/

  â”œâ”€ raw_data/
  
  â”‚  â”œâ”€ to_be_processed/  # extractor writes JSON here
  
  â”‚  â””â”€ processed_data/         # transformer moves processed JSON here
  
  â””â”€ transformed_data/
  
     â”œâ”€ artists_data/
     
     â”œâ”€ album_data/
     
     â””â”€ songs_data/
     
## ğŸ“¦ Lambda Layer (dependencies)

Build once and attach to both functions:

bash

Copy code

mkdir -p python

pip install -t python spotipy==2.23.0 pandas==2.2.2 requests urllib3 certifi charset-normalizer idna
zip -r9 spotipy_pandas_layer.zip python

Upload as a Lambda Layer (runtime: Python 3.11) and attach it.

## ğŸ§± IAM (minimal policy)

Attach to both Lambdas (replace YOUR_BUCKET):

json

Copy code
{
  "Version": "2012-10-17",
  "Statement": [
    {"Effect":"Allow","Action":["logs:CreateLogGroup","logs:CreateLogStream","logs:PutLogEvents"],"Resource":"*"},
    {"Effect":"Allow","Action":["s3:GetObject","s3:PutObject"],"Resource":[
      "arn:aws:s3:::YOUR_BUCKET/raw_data/*",
      "arn:aws:s3:::YOUR_BUCKET/transformed_data/*"
    ]},
    {"Effect":"Allow","Action":["s3:ListBucket"],"Resource":"arn:aws:s3:::YOUR_BUCKET"},
    {"Effect":"Allow","Action":["secretsmanager:GetSecretValue"],"Resource":"*"}
  ]
}

## âš™ï¸ Lambda configuration

-data_extraction â€” ENV VARS

-Name	Example/Notes

-BUCKET_NAME	spotify-etl-pipeline-hp (or your bucket)

-RAW_PREFIX	raw_data/to_be_processed/

-CLIENT_ID	Only if using client-credentials

-CLIENT_SECRET	Only if using client-credentials

-SPOTIFY_SECRET_ID	Secrets Manager id with refresh token JSON (opt.)

 Use SpotifyClientCredentials for public endpoints.

For user endpoints, initialize SpotifyOAuth with credentials read from Secrets Manager (refresh-token flow).

data_transformation â€” ENV VARS

Name	Example/Notes

BUCKET_NAME	same as above

RAW_PREFIX	raw_data/to_be_processed/

PROCESSED_PREFIX	raw_data/processed_data/

TGT_PREFIX	transformed_data/

Trigger: S3 ObjectCreated on RAW_PREFIX.

Important normalization (release dates):

python

Copy code
# album_df columns: release_date, release_date_precision âˆˆ {"year","month","day"}

def _parse_release_date(date_str, precision):

    import pandas as pd
    
    if pd.isna(date_str): return pd.NaT
    
    if precision == "year":  return pd.to_datetime(f"{date_str}-01-01", errors="coerce")
    
    if precision == "month": return pd.to_datetime(f"{date_str}-01",    errors="coerce")
    
    return pd.to_datetime(date_str, errors="coerce")
    
## â° Scheduling & events

EventBridge rule: rate(1 day) â†’ target data_extraction

S3 Notification: ObjectCreated on raw_data/to_be_processed/ â†’ target data_transformation


## ğŸ§ª Notes & gotchas

Playlist 404s: Some chart playlists arenâ€™t API-exposed in every region. Use Search API to resolve IDs, or snapshot another public editorial list daily and aggregate weekly.

OAuth errors after consent: usually redirect URI mismatch or incorrect client secret. Delete .cache locally and re-auth.

Lambda import errors: Your layer zip must contain a top-level python/ folder and match the Lambda runtime version.

S3 key safety: Avoid : in filenames when composing timestamps.

## ğŸ”’ Security

Rotate your Spotify client secret if itâ€™s ever exposed.

Store secrets (client id/secret, refresh token) in AWS Secrets Manager.

Least-privilege IAM policies; separate roles per Lambda when possible.

## ğŸ“œ License

MIT (or update to your preferred license).

makefile

Copy code

::contentReference[oaicite:0]{index=0}
